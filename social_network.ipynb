{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMCoHNju/0u+0vB09cbPkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hansulich/park/blob/main/social_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "R5P3x_9CEThH",
        "outputId": "b53a9526-1cf5-4a69-ba92-cbd9aeb9cd67"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Social_Network_Ads.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df7330d4194c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1. 데이터 로딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Social_Network_Ads.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Social_Network_Ads.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Hansulich/park/main/Social_Network_Ads.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# 데이터 전처리(preprocessing), Feature 추출\n",
        "# \"Age\"(x1)와 \"EstimatedSalary\"(x2)를 특징 벡터(X)로 사용\n",
        "X = data.iloc[:, [2, 3]].values  # Age와 EstimatedSalary 컬럼\n",
        "y = data.iloc[:, 4].values       # Purchased 컬럼\n",
        "\n",
        "# 학습 데이터를 데이터의 80%(320개), 테스트 데이터를 20%(80개)로 분할 사용\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(len(X))\n",
        "train_size = int(len(X) * 0.8)\n",
        "train_indices = indices[:train_size]\n",
        "test_indices = indices[train_size:]\n",
        "X_train, X_test = X[train_indices], X[test_indices]\n",
        "y_train, y_test = y[train_indices], y[test_indices]\n",
        "\n",
        "# 특징 스케일링을 통한 수렴성 향상(수동 구현)\n",
        "def standardize(X):\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "    return (X - mean) / std, mean, std\n",
        "\n",
        "X_train, mean_train, std_train = standardize(X_train)\n",
        "# 훈련 데이터의 평균과 표준편차로 테스트 데이터 스케일링\n",
        "X_test = (X_test - mean_train) / std_train\n",
        "\n",
        "# 4. 학습데이터에 대해 로지스틱회귀 모델 구성\n",
        "# 예측 함수 : Sigmoid 함수 정의\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# 경사하강법을 이용한 로지스틱 회귀 구현\n",
        "def gradient_descent(X, y, learning_rate=0.01, iterations=10000):\n",
        "    m, n = X.shape\n",
        "    # 편향항 추가\n",
        "    X_with_bias = np.c_[np.ones((m, 1)), X]\n",
        "    # 가중치 초기화\n",
        "    weights = np.zeros(n + 1)\n",
        "\n",
        "    # 경사하강법\n",
        "    for i in range(iterations):\n",
        "        # 예측값 계산\n",
        "        z = np.dot(X_with_bias, weights)\n",
        "        predictions = sigmoid(z)\n",
        "\n",
        "        # 그래디언트 계산\n",
        "        gradient = np.dot(X_with_bias.T, (predictions - y)) / m\n",
        "\n",
        "        # 가중치 업데이트\n",
        "        weights = weights - learning_rate * gradient\n",
        "\n",
        "        # 교차 엔트로피 오차 계산 (모니터링용, 선택사항)\n",
        "        if i % 1000 == 0:\n",
        "            z = np.dot(X_with_bias, weights)\n",
        "            predictions = sigmoid(z)\n",
        "            loss = -np.mean(y * np.log(predictions + 1e-15) + (1 - y) * np.log(1 - predictions + 1e-15))\n",
        "            print(f\"반복 횟수 {i}, 손실: {loss}\")\n",
        "\n",
        "    return weights\n",
        "\n",
        "# 5. 경사하강법을 이용해서 모델 학습하고, 파라미터 값 출력\n",
        "weights = gradient_descent(X_train, y_train)\n",
        "w0, w1, w2 = weights\n",
        "print(f\"경사하강법 파라미터: w0 = {w0}, w1 = {w1}, w2 = {w2}\")\n",
        "\n",
        "# 6. 모델의 시각화\n",
        "def plot_decision_boundary(X, y, weights, title):\n",
        "    # 여백을 포함한 최소/최대값 설정\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "    # 격자 생성\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01),\n",
        "                          np.arange(x2_min, x2_max, 0.01))\n",
        "\n",
        "    # 격자 점에 대한 예측\n",
        "    X_grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "    X_grid_with_bias = np.c_[np.ones((X_grid.shape[0], 1)), X_grid]\n",
        "    probs = sigmoid(np.dot(X_grid_with_bias, weights))\n",
        "    probs = probs.reshape(xx1.shape)\n",
        "\n",
        "    # 결정 경계선 시각화\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx1, xx2, probs, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "    plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black')\n",
        "\n",
        "    # 데이터 포인트 시각화\n",
        "    plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='구매 안함')\n",
        "    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='구매함')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('나이 (표준화)')\n",
        "    plt.ylabel('예상 연봉 (표준화)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# 훈련 데이터에 대한 결정 경계선 플롯\n",
        "plot_decision_boundary(X_train, y_train, weights, \"로지스틱 회귀 (훈련 데이터) - 경사하강법\")\n",
        "\n",
        "# scikit-learn Library를 이용, 모델 학습하고, 파라미터 값 출력\n",
        "sk_model = linear_model.LogisticRegression(random_state=42)\n",
        "sk_model.fit(X_train, y_train)\n",
        "\n",
        "# 파라미터 추출 (편향 = w0, 계수 = [w1, w2])\n",
        "sk_w0 = sk_model.intercept_[0]\n",
        "sk_w1, sk_w2 = sk_model.coef_[0]\n",
        "print(f\"Scikit-learn 파라미터: w0 = {sk_w0}, w1 = {sk_w1}, w2 = {sk_w2}\")\n",
        "\n",
        "# scikit-learn을 이용한 모델 시각화\n",
        "# scikit-learn 모델을 위한 시각화 함수\n",
        "def plot_decision_boundary_sklearn(X, y, model, title):\n",
        "    # 여백을 포함한 최소/최대값 설정\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "    # 격자 생성\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01),\n",
        "                          np.arange(x2_min, x2_max, 0.01))\n",
        "\n",
        "    # 격자 점에 대한 예측\n",
        "    X_grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "    probs = model.predict_proba(X_grid)[:, 1]\n",
        "    probs = probs.reshape(xx1.shape)\n",
        "\n",
        "    # 결정 경계선 시각화\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx1, xx2, probs, alpha=0.3, cmap=plt.cm.RdBu)\n",
        "    plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black')\n",
        "\n",
        "    # 데이터 포인트 시각화\n",
        "    plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='구매 안함')\n",
        "    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='green', label='구매함')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('나이 (표준화)')\n",
        "    plt.ylabel('예상 연봉 (표준화)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# 훈련 데이터에 대한 시각화\n",
        "plot_decision_boundary_sklearn(X_train, y_train, sk_model, '로지스틱 회귀 (훈련 데이터) - Scikit-learn')\n",
        "\n",
        "# 테스트 데이터에 대한 시각화\n",
        "plot_decision_boundary_sklearn(X_test, y_test, sk_model, '로지스틱 회귀 (테스트 데이터) - Scikit-learn')\n",
        "\n",
        "# 추가 부분: 테스트 데이터에 대한 모델 평가 / 도움 받을것\n",
        "y_pred = sk_model.predict(X_test)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print(f\"테스트 데이터에 대한 모델 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 경사하강법 모델을 이용한 예측\n",
        "X_test_with_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
        "gd_predictions = sigmoid(np.dot(X_test_with_bias, weights))\n",
        "gd_y_pred = (gd_predictions >= 0.5).astype(int)\n",
        "gd_accuracy = np.mean(y_test == gd_y_pred)\n",
        "print(f\"경사하강법 모델의 테스트 데이터에 대한 정확도: {gd_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tB81oOnpE8-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}